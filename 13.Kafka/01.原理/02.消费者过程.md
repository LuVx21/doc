<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [常见参数](#常见参数)
- [消费者组](#消费者组)
- [消费者](#消费者)
- [原理](#原理)
    - [基本流程](#基本流程)
    - [再均衡](#再均衡)
- [可靠性保证](#可靠性保证)
- [位移管理](#位移管理)
    - [自动提交](#自动提交)
    - [手动提交偏移量](#手动提交偏移量)
- [__consumer_offsets](#__consumer_offsets)
- [使用](#使用)
    - [线程不安全](#线程不安全)
    - [监听消费组再均衡](#监听消费组再均衡)
    - [重试](#重试)
- [QA](#qa)

<!-- /TOC -->
</details>

## 常见参数

**fetch.min.bytes**

配置Consumer一次拉取请求中能从Kafka中拉取的最小数据量, 默认为1B, 如果小于这个参数配置的值, 就需要进行等待, 直到数据量满足这个参数的配置大小. 调大可以提交吞吐量, 但也会造成延迟

**fetch.max.bytes**

一次拉取数据的最大数据量, 默认为52428800B, 也就是50M, 但是如果设置的值过小, 甚至小于每条消息的值, 实际上也是能消费成功的

**fetch.message.max.bytes**


**fetch.wait.max.ms**

若是不满足`fetch.min.bytes`时, 等待消费端请求的最长等待时间, 默认是500ms

**max.poll.records**

单次poll调用返回的最大消息记录数, 如果处理逻辑很轻量, 可以适当提高该值. 一次从kafka中poll出来的数据条数,`max.poll.records`条数据需要在在session.timeout.ms这个时间内处理完, 默认值为500

**session.timeout.ms**

默认值是10s, 该参数是 Consumer Group 主动检测 (组内成员comsummer)崩溃的时间间隔. 若超过这个时间内没有收到心跳报文, 则认为此消费者已经下线. 将触发再均衡操作

**max.poll.interval.ms**

两次拉取消息的间隔, 默认5分钟; 通过消费组管理消费者时, 该配置指定拉取消息线程最长空闲时间, 若超过这个时间间隔没有发起poll操作, 则消费组认为该消费者已离开了消费组, 将触发再均衡操作

若超过这个时间则报如下异常:

```
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
```
即: 无法完成提交, 因为组已经重新平衡并将分区分配给另一个成员. 这意味着对poll()的后续调用之间的时间比配置的max.poll.interval.ms长, 这通常意味着poll循环花费了太多的时间来处理消息.

可以通过增加`max.poll.interval.ms`来解决这个问题, 也可以通过减少在poll()中使用`max.poll.records`返回的消息数来解决这个问题

---

`consumer.poll(100)`, 100 毫秒是一个超时时间, 一旦拿到足够多的数据(`fetch.min.bytes` 参数设置), 会立即返回. 如果没有拿到足够多的数据, 会阻塞100ms, 但不会超过100ms就会返回


## 消费者组

Kafka提供的可扩展且具有容错性的消费者机制

消费者组是一个由多个消费者实例构成的组. 同一个组下的每个实例都共享一个公共的ID, 即Group ID, 并被分配订阅不同的分区.

所有消费者共同订阅若干个主题, 协调在一起来消费所订阅主题的所有分区.

每个分区只能由同一个消费组内的一个消费者实例来消费.

当某个实例挂掉的时候, 其他实例会自动地承担起它负责消费的分区

## 消费者

一个消费者可以消费多个topic的消息, 也可以消费同一个topic的多个分区的消息

一个分区可以被多个消费者消费, 但不能被同一个消费组的多个消费者消费, 换句话说, 如果多个消费者要消费同一个分区, 那这些消费者要分布在不同的消费者组中

如果一个消费组中消费者的数量多于分区数, 则会出现消费者空闲的情况, 因此不建议创建比分区数多的消费者

基于消费者组的概念, 可以发现某个分区的消息可以被不同的消费组多次消费, 所以不同的消费组消费到哪个offset是怎样记录的?

被消费的 Partition 会为每个消费组保存一个偏移量, 记录消费到的位置, 如图:

![](https://gitee.com/LuVx/img/raw/master/kafka/kafka_Partition与消费模型.png)

这些信息都记录在: `__consumer_offsets`, 系统内部topic

* 无需手动干预, 主要作用是负责注册消费者(保存消费者元数据)以及保存位移值
* 内部存储消费组对某个topic的某个分区的消费进度, 以`消费组名+topic名+分区 id`为key计算出存储 offset 的分区id
* Kafka的`GroupCoordinator`组件提供对该主题完整的管理功能, 包括该主题的创建, 写入, 读取和Leader维护等

消息的删除: 消息的删除与是否消费无关, 直到过期, 在有效期内可以被任何消费组随意消费, 之后到达过期时间被自动删除

消费消息时, 以下三个配置是必需的:

* `bootstrap.servers`: 指定 broker 的地址清单
* `key.deserializer`: 指定键的反序列化器
* `value.deserializer`: 指定值的反序列化器

## 原理

consumer 采用 `pull(拉)`模式从 broker 中读取数据,

`push`模式的消费形式无法满足不同消费能力的消费者, 因为消费速率由broker控制, 而`pull`模式则可以由消费者自主控制消费速率

### 基本流程

pull 方式拉取消息, 向`__consumer_offset` topic中发送消息, 记录消费者对分区的消费偏移量, 即消费到哪个位置

这个位置在再均衡时发挥着重要作用, 因为再均衡后某分区对应的消费者可能就不是之前的那一个, 因此就会去这个特殊的 topic 中, 以`消费组名+topic 名+分区 id`找到上一次消费的位置继续消费, 因此正确提交消费偏移量是至关重要的

### 再均衡

为消费者分配订阅的分区

消费组内增减消费者时, 增加的消费者会消费一个或多个分区, 减去的消费者负责的分区会分给其他消费者, 这样的一个维护过程被称为再均衡

在此期间, 无法对消费者提供服务, 会造成短暂的不可用, 降低性能

再均衡的触发条件:
1. 组成员发生变更(新 consumer 加入组, 已有 consumer 主动离开组或已有 consumer 崩溃)
2. 订阅主题数发生变更
3. 订阅主题的分区数发生变更

> 异常情况: 消息处理耗时或拉取量过多, 导致处理时间超过了`max.poll.interval.ms`的配置时间, 认为消费者挂掉

过程:

阶段 1: 选择组协调器

`Math.abs(groupID.hashCode()) % numPartitions`, 定位到`__consumer_offsets` 的分区上, 这个分区的 leader 副本所在的 broker 即是组协调器

阶段 2: 加入消费组

组协调器会选择一个 consumer 作为 leader 协调器(consumer Leader), 并将消费组情况发送过来, 这个 leader 协调器会负责制定分区方案

阶段 3: sync group

发送SyncGroupRequest给组协调器, 之后组协调器根据分配方案下发给每个消费者

## 可靠性保证

不丢失不重复

消费偏移量提交不正确, 如小于最后一次消费消息的偏移量, 那么这`提交的~实际消费的`两个偏移量间的消息则会重复消费, 如果大于, 则`实际消费的~提交的`两个偏移量之间的消息会丢失

消息丢失: 如获取到某消息后, 自动提交了offset, 但出现异常导致没有成功消费该消息, 恢复后就会从下一个offset开始消费

消息重复: 上一次提交偏移量后, 下一次提交之前发生再均衡, 之后就会从最后一次提交的偏移量后开始消费, 而这个偏移量到发生再均衡时之间的消息都会重复消费, 原因: 已经消费了数据, 但是offset没有成功提交

解决方案:

每次拉取的消息记录数`max.poll.records`为100, 消息处理过于耗时导致时长大于拉取间隔时间或者session时间, 导致再均衡发生重复消费

解决办法:

* 减少每次拉取的消息记录数和增大poll之间的时间间隔
* 拉取到消息之后异步处理(保证成功消费)

## 位移管理

### 自动提交

```Java
// 是否开启自动提交
props.put("enable.auto.commit", "true");
// 自动提交时间间隔
props.put("auto.commit.interval.ms", "1000");
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
}
```

### 手动提交偏移量

手动提交的话, 也是有可能带来重复消费的风险, 如消费完成了, 提交offset时出现异常, 恢复后再次消费了该消息

**同步提交**

```Java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
    consumer.commitSync();
}
```

如果提交失败, 同步方式会进行重试, 最大限度保证提交成功, 当然伴随着吞吐量的下降

**异步提交**

```Java
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    KafkaUtils.print(records);
    consumer.commitAsync(
            (offsets, exception) -> {
                if (exception != null) {
                    log.error("commit exception! offset:{}", offsets);
                }
            }
    );
}
```

异步方式在提交失败时不会进行重试, 这是异步模式本身决定的, 前一提交的失败不会阻塞后一提交,

如果后一提交成功, 对前一提交进行重试, 如果重试成功则会覆盖掉后面的offset

**提交指定偏移量**

```Java
Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>(8);
while (true) {
    ConsumerRecords<String, String> records1 = consumer.poll(Duration.ofMillis(100));
    // KafkaUtils.print(records);
    for (ConsumerRecord<String, String> record : records1) {
        TopicPartition tp = new TopicPartition(record.topic(), record.partition());
        OffsetAndMetadata om = new OffsetAndMetadata(record.offset() + 1, "nothing");
        offsets.put(tp, om);
    }
    // consumer.commitSync(offsets);
    consumer.commitAsync(offsets, null);
}
```

同样的也支持同步/异步方式

## __consumer_offsets

默认 50 个分区

这个 topic中的消息格式:

key: `group.id+topic+分区号`, 消费组名即是`group.id`

value: offset的值

对每个 `group.id`做哈希求模运算`Math.abs(groupID.hashCode()) % numPartitions`, 从而将负载分散到不同的分区上

[阅读](https://cloud.tencent.com/developer/article/1846774)

## 使用

### 线程不安全

Java Consumer是双线程的设计. 一个线程是用户主线程, 负责获取消息; 另一个线程是心跳线程, 负责向Kafka汇报消费者存活情况. 将心跳单独放入专属的线程, 能够有效地规避因消息处理速度慢而被视为下线的“假死”情况.

单线程获取消息的设计能够避免阻塞式的消息获取方式. 单线程轮询方式容易实现异步非阻塞式, 这样便于将消费者扩展成支持实时流处理的操作算子. 因为很多实时流处理操作算子都不能是阻塞式的. 另外一个可能的好处是, 可以简化代码的开发. 多线程交互的代码是非常容易出错的.

Kafka 的 Consumer 客户端是线程不安全的, 为了保证线程安全, 并提升消费性能, 可以在 Consumer 端采用类似 Reactor 的线程模型来消费数据

### 监听消费组再均衡

代码如下:

```Java
consumer.subscribe(Arrays.asList(KafkaConfig.topic), new ConsumerRebalanceListener() {
            /**
             * 停止消费消息后, 再均衡前调用
             */
            @Override
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                log.info("再均衡开始:{}", LocalDateTime.now());
                consumer.commitSync();
            }

            /**
             * 再均衡后, 开始消费消息前调用
             */
            @Override
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                log.info("再均衡结束:{}", LocalDateTime.now());
                for (TopicPartition partition : partitions) {
                    // 定位到最近提交的 offset 位置继续消费
                    consumer.seek(partition, getOffset(partition));
                }
            }
        }
);
```

### 重试

kafka本身并不支持消息重试, 消费时发生异常, 通过捕获异常然后再将此消息重新发送至远程topic, 让其他consumer重新消费

可以设置最大重试次数, 达到之后, 会发送到自定义的死信队列, 做最后的兜底处理

因为有重试操作, 需要保证幂等, 只要可能发生消息重复的场景都需要保证幂等,如生产重复, 再平衡时重复

可参考RocketMQ消费幂等的解决方案: 为消息指定不会重复的唯一标识

## QA

**消费者组的位移提交机制**

