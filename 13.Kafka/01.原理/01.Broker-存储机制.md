<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [日志段](#日志段)
- [index](#index)
- [log](#log)
  - [message格式](#message格式)
- [leader-epoch-checkpoint](#leader-epoch-checkpoint)

<!-- /TOC -->

</details>

## 日志段

Kafka的消息是存储在文件系统上, 其高效的实现是基于顺序读写

![](https://gitee.com/LuVx/img/raw/master/kafka/kafka-log.png)

在一个broker中, 一个topic分为多个partition, 一个partition分为多个segment, 一个segment对应多个文件

创建topic后, 默认在 `/tmp/kafka-logs`目录下能看到相关内容

其中, 分区对应名为类似 `topicName-0`结构的目录, 其中的数字表示分区的id, 意义为 `<topic_name>-<partition_id>`

在此目录内部存在多组命名类似于:

```
00000000000000000000.index
00000000000000000000.timeindex
00000000000000000000.log
```

的文件, 这些文件就是一个segment的组成, 前者为索引文件, 后者为数据文件

文件以当前 segment 的第一条消息的 offset 命名, 如上是分区起始的segment

偏移量是一个64位的长整型数值, 固定是20位数字, 长度未达到, 用0进行填补

| 类别                    | 作用                     | 命令                                                                              |
| ----------------------- | ------------------------ | --------------------------------------------------------------------------------- |
| .index                  | 偏移量索引文件           | kafka-dump-log.sh --files ./00000000000000000000.index                            |
| .timeindex              | 时间戳索引文件           | kafka-dump-log.sh --files ./00000000000000000000.timeindex                        |
| .log                    | 日志文件                 | kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.log |
| .snapshot               | 日志快照                 |                                                                                   |
| leader-epoch-checkpoint | 用于副本同步的检查点文件 |                                                                                   |

这3个文件采用了分片和索引机制, 而文件名起到索引的作用, 其中 `.index`文件存储大量的索引信息, 指出特定offset的消息的位置, `.log`文件存储大量的数据

微观层面上, 每个分区对应一个[Log](https://github.com/apache/kafka/blob/b7c8490cf47b0c18253d6a776b2b35c76c71c65d/core/src/main/scala/kafka/log/Log.scala#L236)对象, 在磁盘中就是上文说的一个目录, 子目录下面会有多组日志页, 对应一个[LogSegment](https://github.com/apache/kafka/blob/b7c8490cf47b0c18253d6a776b2b35c76c71c65d/core/src/main/scala/kafka/log/LogSegment.scala#L56)对象

配置参数:

| 配置项                   | 默认值 | 说明                                                                           |
| ------------------------ | ------ | ------------------------------------------------------------------------------ |
| log.index.size.max.bytes | 10MB   | 触发偏移量索引文件或时间戳索引文件分段字节限额                                 |
| log.index.interval.bytes | 4K     | 增加索引项字节间隔密度, 会影响索引文件中的区间密度和查询效率                   |
| log.segment.bytes        | 1G     | 日志文件最大值                                                                 |
| log.roll.ms              |        | 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值允许的最大范围, 毫秒维度 |
| log.roll.hours           | 7天    | 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值允许的最大范围, 小时维度 |

触发日志开启新分页的条件:

* 当前日志段日志文件大小超过了log.segment.bytes配置的大小(日志页超过了大小)
* 当前日志段中索引文件与时间戳索引文件超过了log.index.size.max.bytes配置的大小(日志页索引文件超过大小)
* 当前日志段中消息的最大时间戳与系统的时间戳差值超过了log.roll.ms配置的毫秒值
* 当前日志段中消息的最大时间戳与当前系统的时间戳差值超过log.roll.hours配置的小时值, 优先级比log.roll.ms低
* 追加的消息的偏移量与当前日志段中的之间的偏移量差值大于Interger.MAX_VALUE, 意思就是因为要追加的消息偏移量不能转换为相对偏移量. 原因在于在偏移量索引文件中, 消息基于baseoffset的偏移量使用4个字节来表示.

## index

kafka的index采用的是稀疏索引, 而index文件和timeindex文件是一一对应的

index文件

```
offset: 35 position: 4961 // 4byte+4byte
offset: 261 position: 24300
```

timeindex文件

```
timestamp: 1636617435892 offset: 35 // 8byte+4byte
timestamp: 1636617435952 offset: 261
```

内部维护了一个ConcurrentSkipListMap来保存在每个日志分段

在查找指定 offset 的消息时, 先通过二分法定位LogSegment, 然后去 index 文件二分找到不大于目标 offset 的offset及 position, 之后从此处开始顺序查找

而 timeindex 则会多一步查看所有日志文件最大时间戳largestTimeStamp的操作, 找到offset 后进行上面的操作

## log

```
baseOffset: 0 lastOffset: 31 count: 32 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1636617435886 size: 4961 magic: 2 compresscodec: NONE crc: 3491097385 isvalid: true
baseOffset: 32 lastOffset: 35 count: 4 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 4961 CreateTime: 1636617435892 size: 674 magic: 2 compresscodec: NONE crc: 1015769393 isvalid: true
```

baseOffset~lastOffset: LogSegment的起始消息的 offset

CreateTime: timeindex 文件中的时间戳不一定递增, 除非 `log.message.timestamp.type`设置为 `LogAppendTime` ,如果是 `CreateTime`, 就会出现乱序

size: 4961K

compresscodec: 压缩类型

kafka提供了两种清理策略: 日志删除和日志压缩, 可以通过参数 `log.cleaner.policy`进行配置, 参数可选 `[compact, delete]`

**日志删除:**

| 配置                            | 默认值     | 说明                                           |
| ------------------------------- | ---------- | ---------------------------------------------- |
| log.retention.check.interval.ms | 300000毫秒 | 日志清理器检查日志是否符合删除条件的频率(毫秒) |
| log.retention.bytes             | -1         | 保留日志文件的最大值                           |
| log.segment.bytes               | 1073741824 | 单个日志文件的最大大小(KB)                     |
| log.retention.hours             | 168小时    | 日志保留的时间(小时)                           |
| log.retention.minutes           |            | 日志保留的时间(分钟)                           |
| log.retention.ms                |            | 日志保留的时间(毫秒)                           |
| file.delete.delay.ms            | 60000毫秒  | 从磁盘中删除的延迟时间(毫秒)                   |

**日志压缩: **

针对每个消息的key进行整合, 对于有相同key的不同的value值, 只保留最后一个版本.
也支持对单个的topic进行配置清理策略, 参数 `cleaner.policy`, 压缩策略通过 `compression.type`进行指定, 可选值为 `[none, gzip, snappy, lz4, zstd]`

### message格式

一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成

header部分由1 byte的magic(文件格式)和4 byte的CRC32(用于判断body消息体是否正常)构成.

当magic的值为1的时候, 会在magic和crc32之间多一个字节的数据: attributes(保存一些相关属性, 比如是否压缩, 压缩格式等等);

如果magic的值为0, 那么不存在attributes属性, body是由N个字节构成的一个消息体, 包含了具体的key/value消息.

2:

消息由一个固定长度的头部和可变长度的字节数组组成.

头部包含了一个版本号和 CRC32 校验码.

- 消息长度: 4 bytes (value: 1 + 4 + n)
- 版本号: 1 byte, magic(文件格式)
- CRC 校验码: 4 bytes, 用于判断body消息体是否正常
- 具体的消息: n bytes

[一文看懂Kafka消息格式的演变](https://mp.weixin.qq.com/s?__biz=MzU0MzQ5MDA0Mw==&mid=2247483983&idx=1&sn=1c2bd11df195f84e5433512f6b2695e8&chksm=fb0be8dbcc7c61cda63c599769b38a78c08e51ab8a2943985040014dcbcc1cbe1547d3f70ee6&scene=21#wechat_redirect)

## leader-epoch-checkpoint

```conf
0			# 版本号
2			# 下面的记录数
0 0			# [epoch, offset]
4 7179704	# [epoch, offset]
# epoch表示leader的版本号, 从0开始, leader变更过1次epoch就会+1
# offset表示对应该epoch版本的leader写入第一条消息的offset
```
