<details>
<summary>点击展开目录</summary>
<!-- TOC -->


<!-- /TOC -->
</details>

**数据传输的事务定义有哪三种?**

数据传输的事务定义通常有以下三种级别:

* 最多一次: 消息不会被重复发送, 最多被传输一次, 但有可能一次不传输
* 最少一次: 消息不会被漏发送, 最少被传输一次, 但有可能被重复传输
* 精确的一次(Exactly once): 消息既不重复也不丢失, 每个消息都仅被传输一次

**Kafka 判断一个节点是否还活着有哪两个条件?**

1. 节点必须可以维护和 ZooKeeper 的连接, Zookeeper 通过心跳机制检查每个节点的连接
2. 如果节点是个 follower, 它必须能及时的同步 leader 的写操作, 延时不能太久

> 作者: 摘星不想说话<br/>
> 链接: https://juejin.im/post/6844903889003610119<br/>
> 来源: 掘金<br/>
> 著作权归作者所有.<br/>
> 商业转载请联系作者获得授权, 非商业转载请注明出处.

**如果副本长时间不在ISR中, 这说明什么?**

如果副本长时间不在ISR中, 这表示Follower副本无法及时跟上Leader副本的进度.

通常情况下, 需要查看Follower副本所在的Broker与Leader副本的连接情况以及Follower副本所在Broker上的负载情况.

**Kafka为什么不像Redis和MySQL那样支持读写分离?**

*1.使用场景*

对于那种读操作很多而写操作相对不频繁的负载类型而言, 采用读写分离是非常不错的方案: 可以添加很多从库横向扩展, 提升读操作性能.

反观Kafka, 它的主要场景还是在流式生产消费或消息引擎, 而不是以数据存储的方式对外提供读服务, 通常涉及频繁地生产消息和消费消息, 这不属于典型的读多写少场景. 因此, 读写分离方案在这个场景下并不太适合.

*2.副本机制实现方案*

Kafka副本机制使用的是异步消息拉取, 因此存在Leader和Follower之间的不一致性.

如果要采用读写分离, 必然要处理副本滞后引入的一致性问题: 比如如何实现Read-your-writes, 如何保证单调读(Monotonic Reads)以及处理消息因果顺序颠倒的问题.

相反, 如果不采用读写分离, 所有客户端读写请求都只在Leader上处理, 也就没有这些问题了.

当然, 最后的全局消息顺序颠倒的问题在Kafka中依然存在, 常见的解决办法是使用单分区, 其他的方案还有Version Vector, 但是目前Kafka没有提供.

