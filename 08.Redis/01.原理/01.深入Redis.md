---
title: 深入Redis
date: 2018-03-16
tags:
- Redis
- Cache
---
<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [速度快的原因](#速度快的原因)
- [二八定律](#二八定律)
- [热点key](#热点key)
- [问题](#问题)
  - [缓存雪崩](#缓存雪崩)
  - [缓存穿透](#缓存穿透)
  - [缓存击穿](#缓存击穿)
  - [缓存预热](#缓存预热)
  - [缓存更新](#缓存更新)
- [缓存淘汰](#缓存淘汰)

<!-- /TOC -->
</details>

## 速度快的原因

* 基于内存存储
* 单线程, 避免了不必要的上下文切换和各种锁问题
* 多路I/O复用模型, 非阻塞IO(多个连接复用一个线程)

> 基于内存操作, 因此CPU不会成为影响性能的瓶颈, 从而在单线程下足够快, 没有必要采取多线程的方案

单线程无法发挥多核cpu的长处, 实际使用时可配置多实例

## 二八定律

大致意思就是:

80%的业务访问集中在20%的数据上, 而这20%的数据中, 使用频率也存在不同

**缓存命中率**

缓存命中率越高, 加速效果越好, 应用性能表现也越好

Redis中使用`info`命令, 可以得到很多信息, 其中:
```
keyspace_hits:10
keyspace_misses:5
```
可以计算命中率

## 热点key

如上了排行榜的内容, 都有可能成为热点数据

> [!multi-column]
>> [!question] 危害
>> 1. 流量集中, 达到物理网卡上限, 导致该server其他服务无法使用网络
>> 2. 请求过多, 缓存分片服务被打垮
>> 3. 影响热点数据的服务节点, 甚至导致缓存穿透, 直接影响到DB server
>
>> [!note] 解决方案
>> 1. 读写分离: 缓解单台服务器的压力
>> 2. 服务端缓存: 将少量非常热点的数据在服务器端缓存
>> 3. Redis等专用缓存服务
>> 4. 主动发现热点数据, 均衡化存储(如多个缓存服务器, 热点数据在同一台服务器上)
>>     * Redis的`monitor`命令能够用来统计访问情况, 可以分析出热点数据(如Facebook的`redis-faina`)
>> 5. 熔断策略


## 问题

### 缓存雪崩

场景:

对一批缓存设置了同样的过期时间, 在过期后的某一时间, 大量缓存过期, 原本能访问到缓存的请求都去访问数据库, 即发生大规模缓存穿透, 给数据库造成巨大压力, 继而出现严重的连锁问题.

解决雪崩问题的关键在于避免大量的请求同时访问数据库

在上面的场景中, 缓存同时失效是问题的诱因, 因此合理分配缓存的过期时间即可有效避免雪崩,

即使无法避免, 也可以采用对请求排队的方式来减轻服务器的压力, 但是这种解决方案会造成吞吐量的下降, 不推荐在高并发场景下使用.

还有一种治本的方案是对缓存设置好过期标志, 监测到过期即重建缓存.

方案:
1. 均匀化过期时间
2. 互斥锁: 仅一个线程获取锁后去重建索引
3. 缓存不过期

### 缓存穿透

场景:

某一key根本不存在, 在查询时, 先在缓存中查找, 然后去数据库获取相关数据.白白浪费了两次查找的时间.

可以扩展到整个缓存服务不可用的程度都可统称为缓存穿透

1. 做好参数校验, 初步排除不可能存在于缓存中的key
2. 使用布隆过滤器, 将所有可能存在于缓存中的数据哈希到bitmap中, 缓存中没有并且不存在于此bitmap中的则不去查询数据库
3. 对空结果进行缓存, 为了避免存储过多空对象, 通常会给空对象设置一个过期时间. 但有大量的穿透时会缓存很多空占位

### 缓存击穿

热点数据在缓存过期的时, 大量请求到达数据库

1. 使用互斥锁(mutex key): 仅有一个线程能够获取锁, 然后读库重建缓存, 其他的线程阻塞在获取缓存这里
2. 热点数据永不过期: 如不设置过期时间, 或在 value 中存过期时间, 读取时发现快到过期时间, 异步重建缓存

### 缓存预热

场景:

系统上线后就创建好缓存, 避免初次请求时的长时间响应

### 缓存更新

Redis中默认有6种缓存失效策略, 除此之外, 常见自定义的缓存策略

* 定时清理过期缓存
* 当有请求过来时, 再判断这个请求所用到的缓存是否过期, 过期的话就去底层系统得到新数据并更新缓存

## 缓存淘汰

可以设置内存最大使用量, 当使用量超出时, 会根据数据淘汰策略移出数据.

支持的6种缓存淘汰策略:

| No   | 策略              | 说明                                   |
| ---- | ----------------- | -------------------------------------- |
| 1    | `volatile-lru`    | 淘汰最近最少使用的数据                 |
| 2    | `volatile-lfu`    | 最少使用的数据淘汰                     |
| 3    | `volatile-ttl`    | 即将要过期的数据                       |
| 4    | `volatile-random` | 任意选择数据淘汰                       |
| 5    | `allkeys-lru`     | 所有数据中最近最少使用的数据被淘汰     |
| 6    | `allkeys-lfu`     | 所有数据移除最少使用的key              |
| 7    | `allkeys-random`  | 所有数据中随机选择数据淘汰             |
| 8    | `no-enviction`    | 不淘汰任何数据, 但不可再写入, 默认策略 |

> 4.0版本后增加了`lfu(Least Frequently Used)`2, 6两种
> * `volatile-*`: 是针对配置了过期时间的缓存
> * `allkeys-*`: 当内存不足以容纳新数据时, 针对所有数据集采取淘汰策略
> * `LRU`: Least Recently Used, 最近最少使用
> * `LFU`: Least Frequently Used, 最不经常使用
> * `random`: 随机

**LRU在Redis中的实现**

Redis使用的是近似LRU算法, 它跟常规的LRU算法还不太一样. 近似LRU算法通过随机采样法淘汰数据, 每次随机出5个(默认)key, 从里面淘汰掉最近最少使用的key.

可以通过maxmemory-samples参数修改采样数量,  如: maxmemory-samples 10

maxmenory-samples配置的越大, 淘汰的结果越接近于严格的LRU算法, 但因此耗费的CPU也很高.

Redis为了实现近似LRU算法, 给每个key增加了一个额外增加了一个24bit的字段, 用来存储该key最后一次被访问的时间.

**Redis3.0对近似LRU的优化**

Redis3.0对近似LRU算法进行了一些优化. 新算法会维护一个候选池(大小为16), 池中的数据根据访问时间进行排序, 第一次随机选取的key都会放入池中, 随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中, 直到候选池被放满. 当放满后, 如果有新的key需要放入, 则将池中最后访问时间最大(最近被访问)的移除.

当需要淘汰的时候, 则直接从池中选取最近访问时间最小(最久没被访问)的key淘汰掉就行.

---

**LFU算法**

LFU(Least Frequently Used), 是Redis4.0新加的一种淘汰策略, 它的核心思想是根据key的最近被访问的频率进行淘汰, 很少被访问的优先被淘汰, 被访问的多的则被留下来.

LFU算法能更好的表示一个key被访问的热度. 假如你使用的是LRU算法, 一个key很久没有被访问到, 只刚刚是偶尔被访问了一次, 那么它就被认为是热点数据, 不会被淘汰, 而有些key将来是很有可能被访问到的则被淘汰了. 如果使用LFU算法则不会出现这种情况, 因为使用一次并不会使一个key成为热点数据.
