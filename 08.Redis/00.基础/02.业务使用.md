<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [双写一致性](#双写一致性)
- [客户端](#客户端)
- [QA](#qa)
- [阅读](#阅读)

<!-- /TOC -->
</details>

## 双写一致性

复杂的缓存数据

用到缓存才去算缓存

**如何保证缓存与数据库的双写一致性?**

读的时候, 先读缓存, 缓存没有的话, 就读数据库, 然后取出数据后放入缓存, 同时返回响应.

**缓存不在读时存在的问题**

a读到老数据, b写入MySQL新数据, b更新redis, 然后a将老数据写入redis

setnx

a读到老数据, b写入MySQL新数据, b删除redis, 然后a将老数据写入redis

> 通常在更新数据时不会更新缓存, 而是删除缓存, 一方面代码简单, 另一方面缓存的结构有可能是复合型的

---

更新的时候, 先更新数据库, 然后再删除缓存.

**更新操作存在的问题:**

*先更新数据库, 再删除缓存*

如果缓存删除失败, 数据不一致怎么办

删除缓存过程中, 有个线程来读取数据的话会读到缓存, 这是旧数据

*先删除缓存, 再更新数据库*

删除缓存失败更新数据库吗?

先删除缓存, 在准备更新数据库时, 另一个请求过来, 查询缓存, 缓存为空, 然后读取数据库, 写入缓存, 然后刚才的更新操作完成, 造成缓存是旧的, 数据库是新数据

阅读[缓存更新的设计方法](https://segmentfault.com/a/1190000037509415)

缓存删除失败可尝试的方案:

如果只是偶然的删缓存失败, 这种情况则会出现数据不一致, 但最终会通过redis的ttl来自动修正.
这种问题也有解决办法, 加一个flag表, 在更新db的事务里, 往flag表插入一条记录, 记录redis的key, 若执行删缓存成功, 则调db删flag表中的记录.
另外开一个task轮询flag表, 只要表里有记录, 用task去删redis的key.
这样即使redis挂了以后恢复时都能保证数据一致性, 但是这种方案实现从实际业务出发roi较小.

---

双删策略:

先删除缓存, 更新数据库, 预计数据库更新需要时间t, 然后在提交数据库更新t时间后再次删除缓存

步骤是删除 1 -> 更新 db -> 删除 2, 但这样仍存在问题: 第一次删除后来了读操作A, 会穿透到 DB 取到旧数据, 然后操作 B更新删除一步完成, A 将旧数据写入缓存

此时可以考虑, 在删除 2 后以覆盖方式重建缓存, A 操作使用不覆盖的方式写缓存

一致性要求高:
* 内存队列排队
* 加锁, 更新数据库和删除缓存, 读数据库和更新缓存原子操作

## 客户端

**Jedis**

是老牌的Redis的Java实现客户端, 提供了比较全面的Redis命令的支持.

**Redisson**

实现了分布式和可扩展的Java数据结构, 促使使用者对Redis的关注分离, 提供很多分布式相关操作服务, 例如, 分布式锁, 分布式集合, 可通过Redis支持延迟队列.

**Lettuce**

高级Redis客户端, 用于线程安全同步, 异步和响应使用, 支持集群, Sentinel, 管道和编码器.

基于Netty框架的事件驱动的通信层, 其方法调用是异步的. Lettuce的API是线程安全的, 所以可以操作单个Lettuce连接来完成各种操作

[Redis客户端: Jedis,Redisson,Lettuce](https://www.cnblogs.com/williamjie/p/11287292.html)

## QA

**大key(bigkey)问题**

* 操作 bigkey 耗时增加
* 内存空间分配不均匀
* 计算量增大, 内存资源消耗增大, 网络拥塞可能增大

解决方案:

方案 1: 拆分

* string: 压缩
* big list: list1、list2、...listN
* big hash: 可以做二次的hash, 例如hash%100
* 日期类: key20190320、key20190321、key_20190322

方案 2: 删除 bigkey

不过, 异步删除unlink操作是 Redis 4.0 以后才有的功能, 如果你使用的是 4.0 之前的版本, 当你遇到 bigkey 删除时, 我给你个小建议: 先使用集合类型提供的 SCAN 命令读取数据, 然后再进行删除. 因为用 SCAN 命令可以每次只读取一部分数据并进行删除, 这样可以避免一次性删除大量 key 给主线程带来的阻塞. 例如, 对于 Hash 类型的 bigkey 删除, 你可以使用 HSCAN 命令, 每次从 Hash 集合中获取一部分键值对(例如 200 个), 再使用 HDEL 删除这些键值对, 这样就可以把删除压力分摊到多次操作中, 那么, 每次删除操作的耗时就不会太长, 也就不会阻塞主线程了

1.字符串

一般来说, 对于string类型使用del命令不会产生阻塞.

2.hash

使用hscan命令, 每次获取部分(例如100个)field-value, 再利用hdel删除每个field(为了快速可以使用pipeline).

3.list

Redis并没有提供lscan这样的API来遍历列表类型, 但是提供了`ltrim`这样的命令可以渐进式的删除列表元素, 直到把列表删除.

4.set

使用`sscan`命令, 每次获取部分(例如100个)元素, 在利用srem删除每个元素.

5.sorted set

使用`zscan`命令, 每次获取部分(例如100个)元素, 在利用zremrangebyrank删除元素.

方案 3: 本地缓存

方案 4: 定时清理失效数据

## 阅读
