<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [完全分布式](#完全分布式)
- [伪分布式](#伪分布式)
- [整合HBase](#整合hbase)
- [异常解决](#异常解决)
- [参考](#参考)

<!-- /TOC -->
</details>

## 完全分布式

<details>
<summary>环境变量</summary>

```bash
export HIVE_HOME=/opt/hive
export PATH=$PATH:HIVE_HOME/bin
```
</details>

***
<details>
<summary>配置hive-env.sh</summary>

```bash
cd ./hive/conf
cp hive-env.sh.template hive-env.sh
echo 'HADOOP_HOME=/opt/hadoop' >> hive-env.sh
echo 'HIVE_CONF_DIR=/opt/hive/conf' >> hive-env.sh
echo 'HIVE_AUX_JARS_PATH=/opt/hive/lib' >> hive-env.sh
```
</details>

***
<details>
<summary>配置hive-site.xml</summary>

```bash
# 准备
cp hive-default.xml.template hive-site.xml
mkdir -p ../iotmp
```
```xml
<property>
    <name>system:java.io.tmpdir</name>
    <value>/opt/hive/tmp</value>
</property>
<property>
    <name>system:user.name</name>
    <value>hive</value>
</property>
<property>
    <name>hive.metastore.db.type</name>
    <value>mysql</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://127.0.0.1:3306/hive</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>用户名</value>
 </property>
<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>密码</value>
</property>
```
> 上述是直接增加了属性, 也可以直接将文件中出现的下面变量替换掉
> `${system:java.io.tmpdir}`替换为`/opt/hive/iotmp`
> `${system:user.name}`替换为`hive`
</details>

***

上传`mysql-connector-java-8.0.16.jar`到lib目录, 然后执行:

`./bin/schematool -dbType mysql -initSchema`

启动验证

```bash
# 先启动hdfs和yarn
cd $HADOOP_HOME
./sbin/start-dfs.sh && ./sbin/start-yarn.sh
./bin/hdfs dfs -mkdir -p {/tmp,/user/hive/warehouse}
./bin/hdfs dfs -chmod g+w {/tmp,/user/hive/warehouse}
# 启动hive
$HIVE_HOME/bin/hive
```

分发到其他机器上

各个slave的配置中需要增加:
***
<details>
<summary>配置hive-site.xml</summary>

```xml
<property>
    <name>hive.metastore.uris</name>
    <value>thrift://hadoop-master:9083</value>
</property>
```
</details>

## 伪分布式

完全分布式配置的分发步骤位置

## 整合HBase

```bash
# 只需复制一个jar包
cp $HIVE_HOME/lib/hive-hbase-handler-3.1.2.jar $HBASE_HOME/lib/
```
建表:
```sql
-- hive端执行
create table t_student(id int,name string)
stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties("hbase.columns.mapping"=":key,st1:name")
tblproperties("hbase.table.name"="t_student","hbase.mapred.output.outputtable" = "t_student");
```

插入数据:
```bash
# hbase端插入, 之后去hive端查看
put 't_student','1001','st1:name','zhangsan'
put 't_student','1002','st1:name','lisi'
```

## 异常解决

可能出现的异常:
> Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
> `$HIVE_HOME/bin/hive --service metastore &`
> MetaException(message:Version information not found in metastore.)
> `hive-default.xml hive.metastore.schema.verification=false`

> `错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster`
```xml
<property>
   <name>mapreduce.application.classpath</name>
   <value>/opt/hadoop/share/hadoop/mapreduce/*, /opt/hadoop/share/hadoop/mapreduce/lib/*</value>
</property>
```

***
使用beeline命令行或者Java端操作hive, 都需要启动`hiveserver2`服务, 在启动前, 需配置`core-site.xml`:
```xml
<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>
</property>
```
> 上述配置了`root`用户

浏览器可访问`10002`端口

## 参考

