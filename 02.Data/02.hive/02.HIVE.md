<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [关于](#关于)
    - [使用限制](#使用限制)
- [搭建](#搭建)
- [基本操作](#基本操作)
- [元数据](#元数据)
- [表操作](#表操作)
- [字段](#字段)
- [分区](#分区)
- [函数](#函数)
- [事务](#事务)

<!-- /TOC -->
</details>

## 关于


### 使用限制

1.更新, 事务, 索引, 不支持, 是全表扫描

2.创建表的字段类型和java类型是对应的. 不支持日期类型, 提供转换为字符串类型的函数.

3.查询语句中, 不支持having, 可写嵌套的select来解决; group by后只能是表的定义列名, 不能像mysql那样可以为查询语句为逻辑处理结果声明的别名, 但可为逻辑处理过程语句

4.内置函数查看命令(show functions;desc function 函数名)

5.hive中分托管表和外部表, 不同的主要是在drop时, 托管表, 从hive中删除元数据和表数据; 外部表, 只能删除元数据;

6.hive中加载表数据时, 不审查加载的数据是否符合表的声明模式, 只在查询的时候, 用返回null来标识是否符合表的声明模式

7.hive中通过对表进行分区(包含分桶)来提搞对某个特定日期或者某些日期段的数据查询性能. 表分区实际为表目录下的目录文件. 插入时需指定表分区(静态分区或者动态分区都可以), 因为插入仅仅只是数据文件的移动, 不会做特殊处理.

8.hive中插入不支持 insert into 表名 values的形式存在.可以 load data local input '本地文件路径' into table 表名 [partition(分区字段)]或者 insert [overwrite] table 表名 [partition(分区字段)] select ...from 表名

9.hive中不支持truncate table 表名的形式存在(也包括 delete from 表名), 可通过 hive>dfs -rmr /user/hive/warehouse/表名来清空该表下的数据, 以便保持表元数据信息不丢失; 或者通过create table 表名 like 表名, 也可以.

10.hive中join关联查询, 只能通过from 表1 join 表2 on (等值的关联条件) ,不支持像mysql或者oracle中, 可以from 表1, 表2 where 表1.列 = 表2.列的形式

11.hive中不支持 in (子查询语句), 比如: in (select id from 表名) .可以通过内连接或者 半连接 from 表1 left semi join 表2 on (表1.列名 = 表2.列名), 表2只能在on中出现, 不能在select中引用

12.可以通过explain查看hive sql执行计划及解分成后的mapreduce作业数等信息

13.hive中子查询语句只能出现在from子句中, 其他地方目前不允许

14.hive中在不需要全局排序的情况下, 写排序语句时, 最好用distribute by 表名.字段名 sort by 表名.字段名 asc | desc 的形式, 尽量不用order by形式(只通过一个reduce来完成所有的排序结果)



## 搭建

## 基本操作

```sql
show databases;
use default;
show tables;
create table student(id int, name string);
desc student;
insert into student values(1000,'ss');
```

> hive在hdfs中的结构
> 数据库: 在hdfs中表现为`${hive.metastore.warehouse.dir}`目录下一个文件夹
> 表: 在hdfs中表现为所属db目录下一个文件夹, 文件夹中存放该表中的具体数据

异常:

`Container [pid=30055,containerID=container_1573119367597_0002_01_000005] is running 569641472B beyond the 'VIRTUAL' memory limit. Current usage: 156.5 MB of 1 GB physical memory used; 2.6 GB of 2.1 GB virtual memory used. Killing container.`

参考[这里]](https://my.oschina.net/aibati2008/blog/839233)解决


创建数据库

库在hdfs中的位置

## 元数据

Hive中的表的信息:
```sql
select * from DBS;
select * from TBLS where db_id = 16;
select * from COLUMNS_V2 where cd_id = 26 order by integer_idx;
```

## 表操作

## 字段

## 分区

```sql
alter table table_name add partition_spec [ location 'location1' ]
-- partition_spec:
-- partition (partition_col = partition_col_value, partition_col = partiton_col_value, ...)

alter table table_name drop partition_spec, partition_spec,...
```

## 函数

1. concat(): 拼接
2. collect_set(): 分组后同组自动拼接
3. concat_ws():

```sql
select split('a|b|c|d|','\\|');
select concat('a','b','c');
select concat_ws('|','b','c');
select
    user,
    concat_ws(
        ',',collect_set(concat(order_type,'(',order_number,')')
    ) order
from table
group by user
```


实现分页查询:

如果具有唯一标识效果的字段, 如id等

```sql
select * from user order by id asc limit 10;
```

前一次查询的最大id作为下次筛选条件

```sql
select * from user where id > preId order by id asc limit 10;
```

没有主见性质的字段, 可以使用`row_number()`函数

```sql
select * from (select row_number() over() as row_num, * from (
select * from user
)) where row_num between 2 and 4;
```

> `row_number() over(partition by column order by column)`

## 事务


支持事务操作的配置:
<details>
<summary>hive-site.xml</summary>

```xml
<property>
    <name>hive.support.concurrency</name>
    <value>true</value>
</property>
<property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
</property>
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
</property>
<property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
</property>
<property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
</property>
<property>
    <name>hive.compactor.worker.threads </name>
    <value>1</value>
</property>
```
</details>

http://shzhangji.com/cnblogs/2019/06/11/understanding-hive-acid-transactional-table/


