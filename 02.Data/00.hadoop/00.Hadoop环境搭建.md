<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [完全分布式](#完全分布式)
    - [环境准备](#环境准备)
    - [基础配置](#基础配置)
    - [Hadoop节点配置](#hadoop节点配置)
- [伪分布式](#伪分布式)
- [异常解决](#异常解决)
- [其他配置](#其他配置)
- [参考](#参考)

<!-- /TOC -->
</details>

## 完全分布式

### 环境准备

每台机器上都如下修改:
<details>
<summary>/etc/hosts</summary>

```
192.168.1.1 hadoop-master
192.168.1.2 hadoop-slave1
192.168.1.3 hadoop-slave2
```
> 也可以修改好一个后使用工具分发
</details>


***
依次进入每台机器依照上面配置修改主机名
```bash
hostnamectl set-hostname hadoop-master
```

### 基础配置

安装Java省略

<details>
<summary>关闭防火墙</summary>

```bash
systemctl status firewalld.service
systemctl stop firewalld.service
systemctl disable firewalld.service
```
</details>

***
<details>
<summary>免密登录</summary>

```bash
ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
ssh localhost
```
</details>

***
<details>
<summary>节点互相连通</summary>

```bash
# salve上操作, 信任master的访问
scp root@hadoop-master:/root/.ssh/id_rsa.pub ./
cat ./id_rsa.pub >> ~/.ssh/authorized_keys
rm -rf ./id_rsa.pub
ssh hadoop-slave1 # 在master上执行验证

# master上操作, 信任slave的访问
scp root@hadoop-slave1:/root/.ssh/id_rsa.pub ./
cat ./id_rsa.pub >> ~/.ssh/authorized_keys
rm -rf ./id_rsa.pub
ssh hadoop-master # 在slave上执行验证
```
</details>

### Hadoop节点配置

> 各节点上尽量保持相同状态, 如使用具有相同权限的用户
> 以下将master配置为`NameNode`, 配置文件全在`hadoop/etc/hadoop`目录下

首先hadoop安装文件解压在`/opt/hadoop`

环境变量
<details>
<summary>/etc/profile或~/.bashrc</summary>

```bash
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
```
> 为了方便管理, 可以将上述内容加入`~/.path`中后
> 执行`echo 'source ~/.path' >> ~/.bashrc`
</details>

***
<details>
<summary>配置hadoop-env.sh</summary>

```bash
export JAVA_HOME=/opt/java
export HADOOP_HOME=/opt/hadoop
```
</details>

***
<details>
<summary>配置core-site.xml</summary>

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop-master:8020</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>file:/opt/hadoop/tmp</value>
</property>
```
> 目录默认为`/tmp/{$user}`
> 配置时, 随手创建好目录
</details>

***
<details>
<summary>配置hdfs-site.xml</summary>

```xml
<property>
    <name>dfs.replication</name>
    <value>3</value>
</property>
<property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/opt/hadoop/dfs/name</value>
</property>
<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/opt/hadoop/dfs/data</value>
</property>
<property>
    <name>dfs.namenode.http-address</name>
    <value>0.0.0.0:9870</value>
</property>
<property>
    <name>dfs.namenode.rpc-address</name>
    <value>0.0.0.0:9000</value>
</property>
```
</details>

到此步已经可以启动hdfs:

格式化文件系统(仅第一次执行即可, 不要重复执行):

`hdfs或hadoop namenode -format`

启动hdfs:

`sbin/start-dfs.sh`

浏览器访问: `http://localhost:9870`
> hadoop 3.x版本, 端口变为`9870`, 之前为`50070`

停止hdfs:

`sbin/stop-dfs.sh`

> 以上操作随时可用`jps`命令确认启动状态

***
<details>
<summary>配置mapred-site.xml</summary>

```xml
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>
<property>
    <name>mapred.job.tracker</name>
    <value>http://hadoop-master:8021</value>
</property>
```
> `mapred.job.tracker`默认不写则是local, 伪集群下可不用配置
</details>

***
<details>
<summary>配置yarn-site.xml</summary>

```xml
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop-master</value>
</property>
```
</details>

到此步则可以启动yarn:

启动YARN相关进程:

`sbin/start-yarn.sh`

在`http://localhost:8088`页面查看

停止YARN相关进程:

`sbin/stop-yarn.sh`

**声明NameNode和DataNode的配置**

配置`$HADOOP_HOME/etc/hadooop/workers`, 起到指定datanode节点的位置

```
hadoop-slave1
hadoop-slave2
```

> 先删除里面的`localhost`
> 3.x版本, 文件从`slaves`变为`workers`, 似乎也不用配置`masters`

NameNode节点配置完成, 分发到其他机器上去即可

```bash
scp -r /opt/hadoop hadoop-slave1:/opt/
# salve上的需删除workers内容
rm -rf /opt/hadoop/etc/hadoop/workers
```
> 各slave也需要配置环境变量

## 伪分布式

一台机器上, 既当NameNode, 又当DataNode

基本和上述相同, 不同的如下(其实就是配置中的是机器信息都换成本机):

<details>
<summary>配置core-site.xml</summary>

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:8020</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>file:/opt/hadoop/tmp</value>
</property>
> 如果是对外提供服务, 上述的`localhost`是不行的, 建议写成ip
```
</details>

***
<details>
<summary>配置yarn-site.xml</summary>

```xml
<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>
```
</details>

## 异常解决

dfs启动遇到如下类似的错误时(同样的配置在2.x版本上无异常)
```log
Starting namenodes on [hadoop_master]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
```
可尝试以下解决方案:

<details>
<summary>start-dfs.sh, stop-dfs.sh</summary>

```conf
HDFS_NAMENODE_USER=root
HDFS_DATANODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
HDFS_DATANODE_SECURE_USER=hdfs
```
</details>

***
yarn启动时产生类似于dfs启动时的错误, 解决方案类似
<details>
<summary>start-yarn.sh, stop-yarn.sh</summary>

```conf
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
```
</details>

***
`There are 0 datanode(s) running and 0 node(s) are excluded in this operation`
解决方案:

1. 删除`dfs.datanode.data.dir`下的`current`目录
2. `hdfs namenode -format`, 然后启动

## 其他配置

core-site.xml

```xml
<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>
</property>
```

hdfs-site.xml
[属性](https://hadoop.apache.org/docs/r3.1.4/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)


```xml
<property>
    <name>dfs.namenode.rpc-address</name>
    <value>localhost:8020</value>
</property>
<property>
    <name>dfs.namenode.rpc-bind-host</name>
    <value>0.0.0.0</value>
</property>
```

mapred-site.xml

```xml
<property>
   <name>mapreduce.application.classpath</name>
   <value>/opt/hadoop/share/hadoop/mapreduce/*, /opt/hadoop/share/hadoop/mapreduce/lib/*</value>
</property>

<property>
　　<name>mapreduce.map.memory.mb</name>
　　<value>1536</value>
</property>
<property>
　　<name>mapreduce.map.java.opts</name>
　　<value>-Xmx1024M</value>
</property>
<property>
　　<name>mapreduce.reduce.memory.mb</name>
　　<value>3072</value>
</property>
<property>
　　<name>mapreduce.reduce.java.opts</name>
　　<value>-Xmx2560M</value>
</property>
```

## 参考

