<details>
<summary>点击展开目录</summary>
<!-- TOC -->

- [自行实现](#自行实现)
- [依赖hive](#依赖hive)
    - [表级别](#表级别)
    - [字段级别](#字段级别)
- [存储方案](#存储方案)
- [关系型数据库](#关系型数据库)
    - [图数据库](#图数据库)
- [参考](#参考)

<!-- /TOC -->
</details>


## 自行实现

自行解析sql获取其中的关系,

解析工具有[JSqlParser](https://github.com/JSQLParser/JSqlParser), 阿里 Druid 中的 SQL 解析模块, 但对于语法的支持都有所不足

可以尝试使用 Antlr, 可以自定义语法文件以弥补不足



思路:

1. 解析出目标表及其字段信息(含顺序id)
2. 每进入一个 select 语句, 记录下如 select offset 信息, 初始化 select field 的位置计数器, 初始化 select field 存储容器
3. 逐个解析 select 字段, 获取其中所有最小粒度的字段的数据源, 字段源及别名, 并做好映射
4. 以 select 语句的 offset 作为 select 语句的唯一标识, 解析其 from 部分, 将来源于同一个 from 源的字段和这个数据源组合成映射, 如`select_id + from_src`具有唯一性, 存储于 map, value 则为来源于此 src 的字段
5. 4 中获取到所有的 `select+from_src`-`select fields`(多个 from 源的, 会存在多个这样的映射)
6. 循环或递归方式解析 5 中的结果, 从而得到字段级关系

[源码](https://github.com/LuVx21/coding-usage/tree/master/usage-dataflow/usage-sqlparser)

## 依赖hive

具有局限性

### 表级别

关键类: `org.apache.hadoop.hive.ql.tools.LineageInfo`

类内部具体实现:
```Java
public static void main(String[] args)
        throws IOException, ParseException, SemanticException {
    String query = args[0];
    LineageInfo lep = new LineageInfo();
    lep.getLineageInfo(query);
    for (String tab : lep.getInputTableList()) {
      System.out.println("InputTable=" + tab);
    }
    for (String tab : lep.getOutputTableList()) {
      System.out.println("OutputTable=" + tab);
    }
  }
```

基于上述实现, 使用时有2种方式:

命令行调用方式:
```shell
hadoop jar /usr/local/hive/lib/hive-exec-1.1.0-cdh5.9.0.jar org.apache.hadoop.hive.ql.tools.LineageInfo <sql>
# InputTable=dict_cityinfo
# InputTable=dict_zoneinfo
# OutputTable=cxy7_dw.tmp_zone_info
```

java调用方式:
```Java
import org.apache.hadoop.hive.ql.tools.LineageInfo;
public class Demo {
    public static void main(String[] args) throws Exception {
        String sql = "";
        LineageInfo.main(new String[]{sql});
    }
}
```

### 字段级别

关键类: `org.apache.hadoop.hive.ql.hooks.LineageLogger`


<details>
<summary>配置</summary>

hive-site.xml
```xml
<property>
    <name>hive.exec.post.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.LineageLogger</value>
</property>
```

hive-log4j.properties
```conf
# 默认日志输出在/tmp/${user.home}/hive.log
log4j.logger.org.apache.hadoop.hive.ql.hooks.LineageLogger=INFO
```
</details>

试验:
```sql
create table t_student(id int, name string);
create table t_score(id int, student_id int, name string, score int);
create table t_summary(id int, student_name string, xueke_name string, score int);

insert into table t_summary
select
    R2.id,
    r1.name as xingming,
    concat(r1.name, '.', r2.name) as xueke,
    r2.score as fenshu
from t_student r1
left join t_score r2
    on r1.id = r2.student_id
where
    R1.id = 1
;
```

[分析结果]()

* vertices: 顶点. 代表参与DAG的节点元素, vertexType有`COLUMN`和`TABLE`两个值
* edges: 边. 代表DAG的流向, sources -> targets, edgeType有`PROJECTION(投影)`和`PREDICATE(谓语)`两个值


## 存储方案

## 关系型数据库

[分层数据存储](../07.MySQL/02.设计/分层数据存储.md)

### 图数据库

neo4j


```bash
# console application
<NEO4J_HOME>/bin/neo4j console
# 后台运行
<NEO4J_HOME>/bin/neo4j start
```

http://127.0.0.1:7474
账户密码: neo4j

neo4j://luvx:57687

```
:server connect
:server disconnect
```

```sql
MATCH (n) DETACH DELETE n
CREATE (n:Person {name:'John'}) RETURN n
CREATE (n:Person {name:'Sally'}) RETURN n
CREATE (n:Person {name:'Steve'}) RETURN n
CREATE (n:Person {name:'Mike'}) RETURN n
CREATE (n:Person {name:'Liz'}) RETURN n
CREATE (n:Person {name:'Shawn'}) RETURN n
CREATE (n:Location {city:'Miami', state:'FL'})
CREATE (n:Location {city:'Boston', state:'MA'})
CREATE (n:Location {city:'Lynn', state:'MA'})
CREATE (n:Location {city:'Portland', state:'ME'})
CREATE (n:Location {city:'San Francisco', state:'CA'})
MATCH (a:Person {name:'Shawn'}), (b:Person {name:'Sally'}) MERGE (a)-[:FRIENDS {since:2001}]->(b)
MATCH (a:Person {name:'Shawn'}), (b:Person {name:'John'}) MERGE (a)-[:FRIENDS {since:2012}]->(b)
MATCH (a:Person {name:'Mike'}), (b:Person {name:'Shawn'}) MERGE (a)-[:FRIENDS {since:2006}]->(b)
MATCH (a:Person {name:'Sally'}), (b:Person {name:'Steve'}) MERGE (a)-[:FRIENDS {since:2006}]->(b)
MATCH (a:Person {name:'Liz'}), (b:Person {name:'John'}) MERGE (a)-[:MARRIED {since:1998}]->(b)
```

## 参考

1. [1](http://cxy7.com/articles/2018/05/26/1527300004975.html)

